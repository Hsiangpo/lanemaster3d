# 2026-02-19 18:08 GPU利用率冲高阶段计划（暂停快照）

## 1. 当前状态
- 已按你的要求暂停当前动作，训练会话 `lm3d_train` 已停止。
- 服务器当前无 `torchrun/tools/train.py` 训练进程在跑。
- 最近一次目标仍是把双卡训练平均利用率推进到 80%+，并继续冲 90%。

## 2. 我现在在做的事情
- 目标：定位并消除训练中的“长等待数据批次”问题，让 GPU 不再长时间空转。
- 方法：本地改配置/代码 -> `sftp` 推送远端 -> `tmux` 启动新实验 -> 60 秒窗口统计 GPU 平均利用率 -> 不达标立即切下一组。
- 评估标准：
  - 训练必须正常落盘 `experiments/<exp>/logs/metrics.jsonl`。
  - `both_avg`（双卡平均）作为主指标。
  - 同时看 `metrics.jsonl` 中的 `data_time/iter_time/time_forward/time_backward` 来判断瓶颈。

## 3. 已完成动作与结论
- 远端固定入口已接管并持续可用：`ssh -p 2222 sust@38.127.121.195`。
- 新增本地临时执行/同步工具：
  - `.tmp_remote_exec.py`（远端执行）
  - `.tmp_remote_put.py` / `.tmp_remote_get.py`（远端文件同步）
  - `.tmp_gpu_stats.py`（60 秒窗口利用率统计）
- 已做实验：
  - `exp074`（compile关闭、timing拆分开启、gpc/uncertainty每步计算）
  - 采样结果：`gpu0_avg=45.68`，`gpu1_avg=53.00`，`both_avg=49.34`
  - 结论：仍未达标，主要是数据等待阶段导致平均值被拉低。
- 为继续定位，已新增训练开关（尚未继续跑完验证）：
  - 在 `trainer.py` 增加 `runtime.train_shuffle`（默认 True）
  - 目的：做“顺序读取 vs 随机读取”对照，验证是否存在随机 I/O 导致的数据吞吐瓶颈。

## 4. 接下来的执行计划（恢复后按此顺序）
1. 先跑 `exp076`（`train_shuffle=False`）短窗口验证，确认 `both_avg` 是否明显高于 `exp074`。
2. 若提升明显：
   - 保留顺序读取思路，做受控随机（按块打散）以兼顾吞吐与训练随机性。
   - 再叠加 `num_workers/prefetch_factor` 小步调参。
3. 若提升不明显：
   - 回到 `train_shuffle=True`，集中优化数据读取链路（图像解码与批次准备）。
   - 用同样 60 秒窗口和 `data_time` 证据驱动下一轮。
4. 每轮只改 1~2 个变量，不做大杂烩改动，避免结论失真。

## 5. 风险与控制
- 风险1：并发启动/停止命令可能误杀新进程。
  - 控制：停止与启动改为串行执行，不并发。
- 风险2：预热阶段会造成短时低利用率假象。
  - 控制：固定在“进入稳定迭代后”再采 60 秒窗口。
- 风险3：只看瞬时峰值会误判。
  - 控制：统一以 `both_avg` + `p50` 判定，不用单点峰值。

## 6. 关键文件
- 计划文档：`docs/plans/20260219_1808_gpu-util-plan.md`
- 远端训练器（已加开关）：`/home/sust/zhou/lanemaster3d/lanemaster3d/engine/trainer.py`
- 当前实验配置：`/home/sust/zhou/lanemaster3d/configs/openlane/r50_960x720_exp076.py`

## 7. 2026-02-19 晚间续跑结果（远端）
- 执行环境：
  - SSH 入口：`ssh -p 2222 sust@38.127.121.195`
  - 项目目录：`/home/sust/zhou/lanemaster3d`
  - 预检通过：`bash scripts/remote/check_env.sh`、`bash scripts/remote/check_openlane_data.sh .`
- 实验 `lm3d_exp076_run1`（`train_shuffle=False`）：
  - 60 秒窗口 GPU 统计：`gpu0_avg=82.62`，`gpu1_avg=80.85`，`both_avg=81.73`，`both_p50=96.75`
  - 训练日志：`iter_rows=19`，`last_iter=190`
  - `data_time`：平均 `0.0012s`，最大 `0.0018s`（稳定）
- 实验 `lm3d_exp076_run2`（同配置复跑）：
  - 60 秒窗口 GPU 统计：`gpu0_avg=17.12`，`gpu1_avg=20.00`，`both_avg=18.56`，`both_p50=0.00`
  - 训练日志：`iter_rows=9`，`last_iter=90`
  - `data_time`：平均 `2.3560s`，最大 `6.5685s`（明显抖动）
- 实验 `lm3d_exp077_run1`（`num_workers=16`，`prefetch_factor=6`，`train_shuffle=False`）：
  - 60 秒窗口 GPU 统计：`gpu0_avg=0.00`，`gpu1_avg=14.48`，`both_avg=7.24`，`both_p50=7.50`
  - 训练日志：仅记录到 `iter=10`，不满足稳定采样条件

结论（本轮）：
1. `exp076` 在单次窗口可达 80%+，但复跑稳定性不足，当前不能认定“已稳定达标”。
2. 主要问题仍是间歇性数据等待（`data_time` 秒级抖动），会把 `both_avg` 快速拉低。
3. 直接提高 `num_workers/prefetch_factor`（`exp077`）未带来正收益，暂不建议沿该方向继续加大并发。

下一步（延续本计划）：
1. 固化采样规范：统一在 `iter>=120` 且 `data_time` 连续 5 个日志点 < `0.02s` 后再采 60 秒 GPU 窗口，避免把预热/抖动期混入统计。
2. 优先做数据链路排查而非继续盲调并发：围绕 `OpenLaneDataset` 的缓存命中/批次构建耗时增加分段日志，定位秒级抖动来源。
3. 在完成链路排查前，保留 `exp076` 作为基线配置，不再把 `num_workers` 提到 16。

## 8. 2026-02-19 深夜续跑（远端，exp078 数据链路埋点）
- 代码改动（已同步远端并过针对性测试）：
  - `OpenLaneDataset` 新增可开关样本计时埋点（`runtime.data_probe=True` 时启用）。
  - `metrics.jsonl` 新增 `stage_times`（`time_to_device/time_forward/time_loss/time_backward`）与 `data_probe`（样本级分段均值/峰值）。
  - 修复配置语义不一致：训练数据集真正透传 `data.image_backend`（此前配置里写了 `image_backend='cv2'` 但未生效）。
  - 新增配置：`configs/openlane/r50_960x720_exp078.py`（基于 exp076，开启 `runtime.data_probe=True`）。
- 远端预检：
  - `bash scripts/remote/check_env.sh` 通过。
  - `bash scripts/remote/check_openlane_data.sh .` 通过。
- 远端测试：
  - `pytest -q` 定向用例 7 项通过（数据集埋点、后端参数透传、日志字段写入）。

### 8.1 实验 `lm3d_exp078_probe1`（埋点版，修复前 image_backend 透传）
- 采样条件：满足 `iter>=120` 且最近 5 条 `data_time<0.02s` 后采 60 秒窗口。
- `nvidia-smi dmon`：
  - `gpu0_avg=9.30`，`gpu1_avg=49.28`，`both_avg=29.29`，`both_p50=35.75`
  - `active_seconds=31/60`，`idle_seconds=29/60`，`both_avg_active=56.60`
- `metrics.jsonl`：
  - `iter_rows=19`，`last_iter=190`
  - `data_time avg=0.0006s`，`max=0.0029s`
  - `iter_time avg=1.0735s`，`max=2.3631s`
  - `sample_time_image_mean avg=2.2638s`，`sample_time_sample_total_mean avg=2.3713s`

### 8.2 实验 `lm3d_exp078_probe2`（埋点版，image_backend 透传生效）
- 采样条件：同上（`iter>=120` + 最近 5 条 `data_time<0.02s`）。
- `nvidia-smi dmon`：
  - `gpu0_avg=32.37`，`gpu1_avg=21.50`，`both_avg=26.93`，`both_p50=13.25`
  - `active_seconds=32/60`，`idle_seconds=25/60`，`both_avg_active=49.73`
- `metrics.jsonl`：
  - `iter_rows=15`，`last_iter=150`
  - `data_time avg=0.0015s`，`max=0.0034s`
  - `iter_time avg=2.6676s`，`max=5.2791s`
  - `sample_time_image_mean avg=2.2032s`，`sample_time_sample_total_mean avg=2.6678s`

### 8.3 结论（本轮）
1. 本轮埋点确认：当前“秒级 data_time 抖动”并未出现，`data_time` 在毫秒级；但 GPU 仍存在大量空闲秒（60 秒内约 25~29 秒）。
2. 接通 `image_backend` 后，`sample_time_image_mean` 未出现显著下降（约 2.20s ~ 2.26s），`both_avg` 也未提升到可接受区间（约 27%~29%）。
3. 当前主矛盾已从“主线程等数据”转向“训练步内部耗时波动 + 活跃/空闲交替”，盲目继续调 `num_workers/prefetch_factor` 预计收益很低。

### 8.4 是否继续优化（决策建议）
- 若目标是“把双卡平均利用率稳定推到 80%+”：继续做纯参数微调意义不大，应转到算子/损失路径和 DDP 步内同步行为的剖析（如 PyTorch Profiler + rank 对齐分析）。
- 若目标是“尽快推进实验产出”：建议暂停该方向，先回到稳定基线配置训练，把优化预算转向更直接影响指标的项。
